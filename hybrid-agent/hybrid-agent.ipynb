{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingAPIKeyError",
     "evalue": "No API key provided. Please provide the api_key attribute or set the TAVILY_API_KEY environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMissingAPIKeyError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = getpass.getpass(\u001b[33m\"\u001b[39m\u001b[33mEnter API key for OpenAI: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Initialize the Tavily API client using the loaded or provided API key\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m tavily_client = \u001b[43mTavilyClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTAVILY_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Courses\\AgentsTowardsProduction\\tavily_agent\\venv\\Lib\\site-packages\\tavily\\tavily.py:21\u001b[39m, in \u001b[36mTavilyClient.__init__\u001b[39m\u001b[34m(self, api_key, proxies)\u001b[39m\n\u001b[32m     18\u001b[39m     api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MissingAPIKeyError()\n\u001b[32m     23\u001b[39m resolved_proxies = {\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m: proxies.get(\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;28;01melse\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_HTTP_PROXY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m: proxies.get(\u001b[33m\"\u001b[39m\u001b[33mhttps\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;28;01melse\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_HTTPS_PROXY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     26\u001b[39m }\n\u001b[32m     28\u001b[39m resolved_proxies = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m resolved_proxies.items() \u001b[38;5;28;01mif\u001b[39;00m v} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mMissingAPIKeyError\u001b[39m: No API key provided. Please provide the api_key attribute or set the TAVILY_API_KEY environment variable."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Prompt the user to securely input the API key if not already set in the environment\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY:\\n\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "# Initialize the Tavily API client using the loaded or provided API key\n",
    "tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vector store\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the embeddings model with the default model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize the vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"crm\",  # replace with \"my_custom_index\" for custom documents option\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"supplemental/db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Query the vector index\n",
    "search_results = retriever.invoke(\"robotics use case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of tools our agent will use\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_tavily import TavilyExtract\n",
    "from langchain_tavily import TavilyCrawl\n",
    "\n",
    "# Define the vector search tool\n",
    "vector_search_tool = retriever.as_tool(\n",
    "    name=\"vector_search\",\n",
    "    description=\"\"\"\n",
    "    Perform a vector search on our company's CRM data.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# Define the LangChain search tool\n",
    "search = TavilySearch(max_results=10, topic=\"general\")\n",
    "\n",
    "# Define the LangChain extract tool\n",
    "extract = TavilyExtract(extract_depth=\"advanced\")\n",
    "\n",
    "# Define the LangChain crawl tool\n",
    "crawl = TavilyCrawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the OpenAI foundation models\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# o3-mini-2025-01-31\n",
    "o3_mini = ChatOpenAI(model=\"o3-mini-2025-01-31\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# gpt-4.1\n",
    "gpt_4_1 = ChatOpenAI(model=\"gpt-4.1\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import datetime\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "today = datetime.datetime.today().strftime(\"%A, %B %d, %Y\")\n",
    "\n",
    "# Create the hybrid agent\n",
    "hybrid_agent = create_react_agent(\n",
    "    model=gpt_4_1,\n",
    "    tools=[search, crawl, extract, vector_search_tool],\n",
    "    prompt=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                f\"\"\"\n",
    "        You are a ReAct-style research agent equipped with the following tools:\n",
    "\n",
    "        * **Tavily Web Search**\n",
    "        * **Tavily Web Extract**\n",
    "        * **Tavily Web Crawl**\n",
    "        * **Internal Vector Search** (for proprietary CRM data)\n",
    "\n",
    "        Your mission is to conduct comprehensive, accurate, and up-to-date research, using a combination of real-time public web information and internal enterprise knowledge.  All answers must be grounded in retrieved information from the tools provided. You are not permitted to make up information or rely on prior knowledge.\n",
    "\n",
    "        **Today's Date:** {today}\n",
    "\n",
    "        **Available Tools:**\n",
    "\n",
    "        1. **Tavily Web Search**\n",
    "\n",
    "        * **Purpose:** Retrieve relevant web pages based on a query.\n",
    "        * **Usage:** Provide a search query to receive up to 10 semantically ranked results, each containing the title, URL, and a content snippet.\n",
    "        * **Best Practices:**\n",
    "            * Use specific queries to narrow down results.\n",
    "                * Example: \"OpenAI's latest product release\" and \"OpenAI's headquarters location\" rather than \"OpenAI's latest product release and headquarters location\"\n",
    "            * Optimize searches using parameters such as `search_depth`, `time_range`, `include_domains`, and `include_raw_content`.\n",
    "            * Break down complex queries into specific, focused sub-queries.\n",
    "\n",
    "        2. **Tavily Web Crawl**\n",
    "\n",
    "        * **Purpose:** Explore a website's structure and gather content from linked pages for deep research and information discovery from a single source.\n",
    "        * **Usage:** Input a base URL to crawl, specifying parameters such as `max_depth`, `max_breadth`, and `extract_depth`.\n",
    "        * **Best Practices:**\n",
    "\n",
    "            * Begin with shallow crawls and progressively increase depth.\n",
    "            * Utilize `select_paths` or `exclude_paths` to focus the crawl.\n",
    "            * Set `extract_depth` to \"advanced\" for comprehensive extraction.\n",
    "\n",
    "        3. **Tavily Web Extract**\n",
    "\n",
    "        * **Purpose:** Extract the full content from specific web pages.\n",
    "        * **Usage:** Provide URLs to retrieve detailed content.\n",
    "        * **Best Practices:**\n",
    "\n",
    "            * Set `extract_depth` to \"advanced\" for detailed content, including tables and embedded media.\n",
    "            * Enable `include_images` if image data is necessary.\n",
    "\n",
    "        4. **Internal Vector Search**\n",
    "\n",
    "        * **Purpose:** Search the proprietary CRM knowledge base.\n",
    "        * **Usage:** Submit a natural language query to retrieve relevant context from the CRM vector store. Contains context about key accounts like Meta, Apple, Google, Amazon, Microsoft, and Tesla.\n",
    "        * **Best Practices:**\n",
    "            * When possible, refer to specific information, such as names, dates, product usage, or meetings.\n",
    "            \n",
    "\n",
    "        **Guidelines for Conducting Research:**\n",
    "\n",
    "        * You may not answer questions based on prior knowledge or assumptions.\n",
    "        * **Citations:** Always support findings with source URLs, clearly provided as in-text citations.\n",
    "        * **Accuracy:** Rely solely on data obtained via provided tools (web or vector store) —never fabricate information.\n",
    "        * **If none of the tools return useful information, respond:**\n",
    "            * \"I'm sorry, but none of the available tools provided sufficient information to answer this question.\"\n",
    "\n",
    "        **Research Workflow:**\n",
    "\n",
    "        * **Thought:** Consider necessary information and next steps.\n",
    "        * **Action:** Select and execute appropriate tools.\n",
    "        * **Observation:** Analyze obtained results.\n",
    "        **IMPORTANT: Repeat Thought/Action/Observation cycles as needed. You MUST only respond to the user once you have gathered all the information you need.**\n",
    "        * **Final Answer:** Synthesize and present findings with citations in markdown format.\n",
    "        \n",
    "        **Example Workflow:**\n",
    "\n",
    "        **Workflow 4: Combine Web Tools and Vector Search**\n",
    "\n",
    "        **Question:** What has Apple publicly shared about their AI strategy, and do we have any internal notes on recent meetings with them?\n",
    "\n",
    "        * **Thought:** I’ll start by looking for Apple’s public statements on AI using a search.\n",
    "        * **Action:** Tavily Web Search with the query \"Apple AI strategy 2024\" and `time_range` set to \"month\".\n",
    "        * **Observation:** Found a recent article from Apple’s newsroom and a keynote transcript.\n",
    "        * **Thought:** I want to read the full content of Apple’s keynote.\n",
    "        * **Action:** Tavily Web Extract on the URL from the search result.\n",
    "        * **Observation:** Extracted detailed content from Apple’s announcement.\n",
    "        * **Thought:** Now, I’ll check our internal CRM data for recent meeting notes with Apple.\n",
    "        * **Action:** Internal Vector Search with the query \"recent Apple meetings AI strategy\".\n",
    "        * **Observation:** Retrieved notes from a Q2 strategy sync with Apple’s enterprise team.\n",
    "        * **Final Answer:** Synthesized response combining public and internal data, with citations.\n",
    "        ---\n",
    "\n",
    "        You will now receive a research question from the user:\n",
    "        \"\"\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"hybrid_agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# Test the hybrid agent\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"Search for the latest news on google relevant to our current CRM data on them\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Stream the agent's response\n",
    "for s in hybrid_agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final output as markdown\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hybrid agent\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"Check for the Google Deal size and find the latest earnings report for them to validate if they are in spending spree\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Stream the agent's response\n",
    "for s in hybrid_agent.stream(inputs, stream_mode=\"values\"):\n",
    "    message = s[\"messages\"][-1]\n",
    "    if isinstance(message, tuple):\n",
    "        print(message)\n",
    "    else:\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the final output as markdown\n",
    "Markdown(message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
